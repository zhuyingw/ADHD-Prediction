{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "df=pd.read_csv(\"upscaling.csv\")    #read file.\n",
    "X1=df[['Still Morning', 'Still Afternoon', 'Still Evening', 'Still Night', 'Running Morning', 'Running Afternoon', 'Running Evening', 'Running Night']]\n",
    "\n",
    "#Checking if the dataframe contains empty cell values.\n",
    "#df.isnull().values.any())    \n",
    "\n",
    "#Output label\n",
    "y=df['ADHD']\n",
    "\n",
    "#Plot features and label in feature visual file\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1)\n",
    "X1 = scaler.transform(X1)\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When C is  1\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.8181818181818182\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[10  2]\n",
      " [ 4 17]]\n",
      "Linear Kernel F1:  0.8500000000000001\n",
      "10 4 2 17\n",
      "Linear Kernel precision is:  0.8095238095238095\n",
      "Linear Kernel recall is:  0.8947368421052632\n",
      "Linear Kernel accuracy is:  0.8181818181818182\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.7575757575757576\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "Poly Kernel F1:  0.7894736842105263\n",
      "10 4 4 15\n",
      "Poly Kernel precision is:  0.7894736842105263\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.7575757575757576\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.7575757575757576\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "RBF Kernel F1:  0.7894736842105263\n",
      "10 4 4 15\n",
      "RBF Kernel precision is:  0.7894736842105263\n",
      "RBF Kernel recall is:  0.7894736842105263\n",
      "RBF Kernel accuracy is:  0.7575757575757576\n",
      "-----------------------\n",
      "When C is  10\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.7575757575757576\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "Linear Kernel F1:  0.7894736842105263\n",
      "10 4 4 15\n",
      "Linear Kernel precision is:  0.7894736842105263\n",
      "Linear Kernel recall is:  0.7894736842105263\n",
      "Linear Kernel accuracy is:  0.7575757575757576\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.7878787878787878\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[11  4]\n",
      " [ 3 15]]\n",
      "Poly Kernel F1:  0.8108108108108109\n",
      "11 3 4 15\n",
      "Poly Kernel precision is:  0.8333333333333334\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.7878787878787878\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.8181818181818182\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[11  3]\n",
      " [ 3 16]]\n",
      "RBF Kernel F1:  0.8421052631578947\n",
      "11 3 3 16\n",
      "RBF Kernel precision is:  0.8421052631578947\n",
      "RBF Kernel recall is:  0.8421052631578947\n",
      "RBF Kernel accuracy is:  0.8181818181818182\n",
      "-----------------------\n",
      "When C is  100\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.7575757575757576\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "Linear Kernel F1:  0.7894736842105263\n",
      "10 4 4 15\n",
      "Linear Kernel precision is:  0.7894736842105263\n",
      "Linear Kernel recall is:  0.7894736842105263\n",
      "Linear Kernel accuracy is:  0.7575757575757576\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.8181818181818182\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[11  3]\n",
      " [ 3 16]]\n",
      "Poly Kernel F1:  0.8421052631578947\n",
      "11 3 3 16\n",
      "Poly Kernel precision is:  0.8421052631578947\n",
      "Poly Kernel recall is:  0.8421052631578947\n",
      "Poly Kernel accuracy is:  0.8181818181818182\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.8484848484848485\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[12  3]\n",
      " [ 2 16]]\n",
      "RBF Kernel F1:  0.8648648648648649\n",
      "12 2 3 16\n",
      "RBF Kernel precision is:  0.8888888888888888\n",
      "RBF Kernel recall is:  0.8421052631578947\n",
      "RBF Kernel accuracy is:  0.8484848484848485\n",
      "-----------------------\n",
      "When C is  1000\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.7575757575757576\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[10  4]\n",
      " [ 4 15]]\n",
      "Linear Kernel F1:  0.7894736842105263\n",
      "10 4 4 15\n",
      "Linear Kernel precision is:  0.7894736842105263\n",
      "Linear Kernel recall is:  0.7894736842105263\n",
      "Linear Kernel accuracy is:  0.7575757575757576\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.7878787878787878\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[11  4]\n",
      " [ 3 15]]\n",
      "Poly Kernel F1:  0.8108108108108109\n",
      "11 3 4 15\n",
      "Poly Kernel precision is:  0.8333333333333334\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.7878787878787878\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.8484848484848485\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[12  3]\n",
      " [ 2 16]]\n",
      "RBF Kernel F1:  0.8648648648648649\n",
      "12 2 3 16\n",
      "RBF Kernel precision is:  0.8888888888888888\n",
      "RBF Kernel recall is:  0.8421052631578947\n",
      "RBF Kernel accuracy is:  0.8484848484848485\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.30, \n",
    "random_state= 42)\n",
    "\n",
    "# authroized_or_not = (y == 0) | (y == 1)\n",
    "# X = X_train[authroized_or_not]\n",
    "# y = y_train[authroized_or_not]\n",
    "\n",
    "\n",
    "# SVM Classifier model\n",
    "C = [1,10,100,1000]\n",
    "y_predict = []\n",
    "for x in C:\n",
    "    print(\"When C is \", x)\n",
    "    print(\"======================\")\n",
    "    print(\"======================\")\n",
    "\n",
    "    name = \"Linear Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    svm_clf = SVC(kernel=\"linear\", C=x) #using C=1\n",
    "    # svm_clf.fit(X, y)\n",
    "    # #predict on test data\n",
    "    # #providing test data for petal length and width and testing the model.\n",
    "    #Actual label is 0.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Linear kernal returns: \", tmp)\n",
    "    \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"Poly Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "\n",
    "    svm_clf = SVC(kernel='poly', degree=2,C=x) #polynomial kernel with degree 2.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Poly kernal returns: \", tmp)\n",
    "\n",
    "        \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"RBF Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    \n",
    "    svm_clf = SVC(kernel='rbf', gamma=1,C=x) #gaussian rbf kernel.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    \n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The RBF kernal returns: \", tmp)\n",
    "\n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# print(\"The average prediction value is\",round(scores.mean(),3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Decision Tree returns:  0.7272727272727273\n",
      "Decision Tree Confusion Matrix: \n",
      "[[10  5]\n",
      " [ 4 14]]\n",
      "Decision Tree F1:  0.7567567567567567\n",
      "10 4 5 14\n",
      "Decision Tree precision is:  0.7777777777777778\n",
      "Decision Tree recall is:  0.7368421052631579\n",
      "Decision Tree accuracy is:  0.7272727272727273\n",
      "=======================\n",
      "Random Forest returns:  0.8484848484848485\n",
      "Random Forest Confusion Matrix: \n",
      "[[12  3]\n",
      " [ 2 16]]\n",
      "Random Forest F1:  0.8648648648648649\n",
      "12 2 3 16\n",
      "Random Forest precision is:  0.8888888888888888\n",
      "Random Forest recall is:  0.8421052631578947\n",
      "Random Forest accuracy is:  0.8484848484848485\n",
      "=======================\n",
      "XGBoost returns:  0.8484848484848485\n",
      "XGBoost Confusion Matrix: \n",
      "[[12  3]\n",
      " [ 2 16]]\n",
      "XGBoost F1:  0.8648648648648649\n",
      "12 2 3 16\n",
      "XGBoost precision is:  0.8888888888888888\n",
      "XGBoost recall is:  0.8421052631578947\n",
      "XGBoost accuracy is:  0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#repeate for decision tree, random forest, XGBoost\n",
    "\n",
    "name = \"Decision Tree\"\n",
    "print(\"=======================\")\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Decision Tree returns: \", tmp)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(\"Decision Tree Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(\"Decision Tree F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"Random Forest\"\n",
    "print(\"=======================\")\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Random Forest returns: \", tmp)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"XGBoost\"\n",
    "print(\"=======================\")\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = tmp = clf.score(X_test,y_test)\n",
    "print(\"XGBoost returns: \", tmp)\n",
    "\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11448\\1377411771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBinaryCrossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=5, activation=\"relu\",input_shape=(8,)),\n",
    "    Dense(units=3, activation=\"relu\"),\n",
    "    Dense(units=1, activation=\"sigmoid\")])\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "predicted = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Accuracy \n",
    "Accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy for NN:\",Accuracy)\n",
    "\n",
    "# Precision\n",
    "Precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Precision for NN:\",Precision)\n",
    "\n",
    "# Recall\n",
    "Recall = metrics.recall_score(y_test, predicted)\n",
    "print(\"Recall for NN:\",Recall)\n",
    "\n",
    "# F1 score\n",
    "F1_score = metrics.f1_score(y_test, predicted)\n",
    "print(\"F1 score for NN:\",F1_score)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.6491\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6810 - accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6667\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Accuracy for NN: 0.76\n",
      "Precision for NN: 0.76\n",
      "Recall for NN: 1.0\n",
      "F1 score for NN: 0.8636363636363636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=4, activation=\"relu\",input_shape=(8,)),\n",
    "    Dense(units=1, activation=\"sigmoid\")])\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "predicted = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Accuracy \n",
    "Accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy for NN:\",Accuracy)\n",
    "\n",
    "# Precision\n",
    "Precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Precision for NN:\",Precision)\n",
    "\n",
    "# Recall\n",
    "Recall = metrics.recall_score(y_test, predicted)\n",
    "print(\"Recall for NN:\",Recall)\n",
    "\n",
    "# F1 score\n",
    "F1_score = metrics.f1_score(y_test, predicted)\n",
    "print(\"F1 score for NN:\",F1_score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
