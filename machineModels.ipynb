{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "df=pd.read_csv(\"banknote_authentication.csv\")    #read file.\n",
    "X1=df[[\"variance\",\"skewness\",\"curtosis\",\"entropy\"]]\n",
    "\n",
    "#Checking if the dataframe contains empty cell values.\n",
    "#df.isnull().values.any())    \n",
    "\n",
    "#Output label\n",
    "y=df['class']\n",
    "\n",
    "#Plot features and label\n",
    "plt.scatter(X1['variance'],y)\n",
    "plt.xlabel(\"Variance\")\n",
    "plt.ylabel(\"Class\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1)\n",
    "X1 = scaler.transform(X1)\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.30, \n",
    "random_state= 42)\n",
    "\n",
    "# authroized_or_not = (y == 0) | (y == 1)\n",
    "# X = X_train[authroized_or_not]\n",
    "# y = y_train[authroized_or_not]\n",
    "\n",
    "\n",
    "# SVM Classifier model\n",
    "C = [1,10,100,1000]\n",
    "y_predict = []\n",
    "for x in C:\n",
    "    print(\"When C is \", x)\n",
    "    print(\"======================\")\n",
    "    print(\"======================\")\n",
    "\n",
    "    name = \"Linear Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    svm_clf = SVC(kernel=\"linear\", C=x) #using C=1\n",
    "    # svm_clf.fit(X, y)\n",
    "    # #predict on test data\n",
    "    # #providing test data for petal length and width and testing the model.\n",
    "    #Actual label is 0.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Linear kernal returns: \", tmp)\n",
    "    \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"Poly Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "\n",
    "    svm_clf = SVC(kernel='poly', degree=2,C=x) #polynomial kernel with degree 2.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Poly kernal returns: \", tmp)\n",
    "\n",
    "        \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"RBF Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    \n",
    "    svm_clf = SVC(kernel='rbf', gamma=1,C=x) #gaussian rbf kernel.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    \n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The RBF kernal returns: \", tmp)\n",
    "\n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# print(\"The average prediction value is\",round(scores.mean(),3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#repeate for decision tree, random forest, XGBoost\n",
    "\n",
    "name = \"Decision Tree\"\n",
    "print(\"=======================\")\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Decision Tree returns: \", tmp)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(\"Decision Tree Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(\"Decision Tree F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"Random Forest\"\n",
    "print(\"=======================\")\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Random Forest returns: \", tmp)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"XGBoost\"\n",
    "print(\"=======================\")\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = tmp = clf.score(X_test,y_test)\n",
    "print(\"XGBoost returns: \", tmp)\n",
    "\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
