{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "df=pd.read_csv(\"temp.csv\")    #read file.\n",
    "X1=df[['Still Morning', 'Still Afternoon', 'Still Evening', 'Still Night', 'Running Morning', 'Running Afternoon', 'Running Evening', 'Running Night']]\n",
    "\n",
    "#Checking if the dataframe contains empty cell values.\n",
    "#df.isnull().values.any())    \n",
    "\n",
    "#Output label\n",
    "y=df['ADHD']\n",
    "\n",
    "#Plot features and label in feature visual file\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1)\n",
    "X1 = scaler.transform(X1)\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When C is  1\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.92\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 4  0]\n",
      " [ 2 19]]\n",
      "Linear Kernel F1:  0.9500000000000001\n",
      "4 2 0 19\n",
      "Linear Kernel precision is:  0.9047619047619048\n",
      "Linear Kernel recall is:  1.0\n",
      "Linear Kernel accuracy is:  0.92\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.96\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 5  0]\n",
      " [ 1 19]]\n",
      "Poly Kernel F1:  0.9743589743589743\n",
      "5 1 0 19\n",
      "Poly Kernel precision is:  0.95\n",
      "Poly Kernel recall is:  1.0\n",
      "Poly Kernel accuracy is:  0.96\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.88\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 3  0]\n",
      " [ 3 19]]\n",
      "RBF Kernel F1:  0.9268292682926829\n",
      "3 3 0 19\n",
      "RBF Kernel precision is:  0.8636363636363636\n",
      "RBF Kernel recall is:  1.0\n",
      "RBF Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "When C is  10\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.92\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  1]\n",
      " [ 1 18]]\n",
      "Linear Kernel F1:  0.9473684210526315\n",
      "5 1 1 18\n",
      "Linear Kernel precision is:  0.9473684210526315\n",
      "Linear Kernel recall is:  0.9473684210526315\n",
      "Linear Kernel accuracy is:  0.92\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.84\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "Poly Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "Poly Kernel precision is:  1.0\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.84\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "RBF Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "RBF Kernel precision is:  1.0\n",
      "RBF Kernel recall is:  0.7894736842105263\n",
      "RBF Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "When C is  100\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.88\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 17]]\n",
      "Linear Kernel F1:  0.918918918918919\n",
      "5 1 2 17\n",
      "Linear Kernel precision is:  0.9444444444444444\n",
      "Linear Kernel recall is:  0.8947368421052632\n",
      "Linear Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.84\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "Poly Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "Poly Kernel precision is:  1.0\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.8\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 6  5]\n",
      " [ 0 14]]\n",
      "RBF Kernel F1:  0.8484848484848484\n",
      "6 0 5 14\n",
      "RBF Kernel precision is:  1.0\n",
      "RBF Kernel recall is:  0.7368421052631579\n",
      "RBF Kernel accuracy is:  0.8\n",
      "-----------------------\n",
      "When C is  1000\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.88\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 17]]\n",
      "Linear Kernel F1:  0.918918918918919\n",
      "5 1 2 17\n",
      "Linear Kernel precision is:  0.9444444444444444\n",
      "Linear Kernel recall is:  0.8947368421052632\n",
      "Linear Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.76\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 5  5]\n",
      " [ 1 14]]\n",
      "Poly Kernel F1:  0.8235294117647058\n",
      "5 1 5 14\n",
      "Poly Kernel precision is:  0.9333333333333333\n",
      "Poly Kernel recall is:  0.7368421052631579\n",
      "Poly Kernel accuracy is:  0.76\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.76\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 5  5]\n",
      " [ 1 14]]\n",
      "RBF Kernel F1:  0.8235294117647058\n",
      "5 1 5 14\n",
      "RBF Kernel precision is:  0.9333333333333333\n",
      "RBF Kernel recall is:  0.7368421052631579\n",
      "RBF Kernel accuracy is:  0.76\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.30, \n",
    "random_state= 42)\n",
    "\n",
    "# authroized_or_not = (y == 0) | (y == 1)\n",
    "# X = X_train[authroized_or_not]\n",
    "# y = y_train[authroized_or_not]\n",
    "\n",
    "\n",
    "# SVM Classifier model\n",
    "C = [1,10,100,1000]\n",
    "y_predict = []\n",
    "for x in C:\n",
    "    print(\"When C is \", x)\n",
    "    print(\"======================\")\n",
    "    print(\"======================\")\n",
    "\n",
    "    name = \"Linear Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    svm_clf = SVC(kernel=\"linear\", C=x) #using C=1\n",
    "    # svm_clf.fit(X, y)\n",
    "    # #predict on test data\n",
    "    # #providing test data for petal length and width and testing the model.\n",
    "    #Actual label is 0.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Linear kernal returns: \", tmp)\n",
    "    \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"Poly Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "\n",
    "    svm_clf = SVC(kernel='poly', degree=2,C=x) #polynomial kernel with degree 2.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Poly kernal returns: \", tmp)\n",
    "\n",
    "        \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"RBF Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    \n",
    "    svm_clf = SVC(kernel='rbf', gamma=1,C=x) #gaussian rbf kernel.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    \n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The RBF kernal returns: \", tmp)\n",
    "\n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# print(\"The average prediction value is\",round(scores.mean(),3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Decision Tree returns:  0.68\n",
      "Decision Tree Confusion Matrix: \n",
      "[[ 6  8]\n",
      " [ 0 11]]\n",
      "Decision Tree F1:  0.7333333333333334\n",
      "6 0 8 11\n",
      "Decision Tree precision is:  1.0\n",
      "Decision Tree recall is:  0.5789473684210527\n",
      "Decision Tree accuracy is:  0.68\n",
      "=======================\n",
      "Random Forest returns:  0.88\n",
      "Random Forest Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 0 16]]\n",
      "Random Forest F1:  0.9142857142857143\n",
      "6 0 3 16\n",
      "Random Forest precision is:  1.0\n",
      "Random Forest recall is:  0.8421052631578947\n",
      "Random Forest accuracy is:  0.88\n",
      "=======================\n",
      "XGBoost returns:  0.8\n",
      "XGBoost Confusion Matrix: \n",
      "[[ 6  5]\n",
      " [ 0 14]]\n",
      "XGBoost F1:  0.8484848484848484\n",
      "6 0 5 14\n",
      "XGBoost precision is:  1.0\n",
      "XGBoost recall is:  0.7368421052631579\n",
      "XGBoost accuracy is:  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#repeate for decision tree, random forest, XGBoost\n",
    "\n",
    "name = \"Decision Tree\"\n",
    "print(\"=======================\")\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Decision Tree returns: \", tmp)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(\"Decision Tree Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(\"Decision Tree F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"Random Forest\"\n",
    "print(\"=======================\")\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Random Forest returns: \", tmp)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"XGBoost\"\n",
    "print(\"=======================\")\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = tmp = clf.score(X_test,y_test)\n",
    "print(\"XGBoost returns: \", tmp)\n",
    "\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
