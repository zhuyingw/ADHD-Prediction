{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(40)\n",
    "\n",
    "df=pd.read_csv(\"upscaling.csv\")    #read file.\n",
    "X1=df[['Still Morning', 'Still Afternoon', 'Still Evening', 'Still Night', 'Running Morning', 'Running Afternoon', 'Running Evening', 'Running Night']]\n",
    "\n",
    "#Checking if the dataframe contains empty cell values.\n",
    "#df.isnull().values.any())    \n",
    "\n",
    "#Output label\n",
    "y=df['ADHD']\n",
    "\n",
    "#Plot features and label in feature visual file\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X1)\n",
    "X1 = scaler.transform(X1)\n",
    "\n",
    "#Normalize features using MinMaxScaler.\n",
    "#Please see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When C is  1\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.92\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 4  0]\n",
      " [ 2 19]]\n",
      "Linear Kernel F1:  0.9500000000000001\n",
      "4 2 0 19\n",
      "Linear Kernel precision is:  0.9047619047619048\n",
      "Linear Kernel recall is:  1.0\n",
      "Linear Kernel accuracy is:  0.92\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.96\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 5  0]\n",
      " [ 1 19]]\n",
      "Poly Kernel F1:  0.9743589743589743\n",
      "5 1 0 19\n",
      "Poly Kernel precision is:  0.95\n",
      "Poly Kernel recall is:  1.0\n",
      "Poly Kernel accuracy is:  0.96\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.88\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 3  0]\n",
      " [ 3 19]]\n",
      "RBF Kernel F1:  0.9268292682926829\n",
      "3 3 0 19\n",
      "RBF Kernel precision is:  0.8636363636363636\n",
      "RBF Kernel recall is:  1.0\n",
      "RBF Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "When C is  10\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.92\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  1]\n",
      " [ 1 18]]\n",
      "Linear Kernel F1:  0.9473684210526315\n",
      "5 1 1 18\n",
      "Linear Kernel precision is:  0.9473684210526315\n",
      "Linear Kernel recall is:  0.9473684210526315\n",
      "Linear Kernel accuracy is:  0.92\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.84\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "Poly Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "Poly Kernel precision is:  1.0\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.84\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "RBF Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "RBF Kernel precision is:  1.0\n",
      "RBF Kernel recall is:  0.7894736842105263\n",
      "RBF Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "When C is  100\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.88\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 17]]\n",
      "Linear Kernel F1:  0.918918918918919\n",
      "5 1 2 17\n",
      "Linear Kernel precision is:  0.9444444444444444\n",
      "Linear Kernel recall is:  0.8947368421052632\n",
      "Linear Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.84\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 6  4]\n",
      " [ 0 15]]\n",
      "Poly Kernel F1:  0.8823529411764706\n",
      "6 0 4 15\n",
      "Poly Kernel precision is:  1.0\n",
      "Poly Kernel recall is:  0.7894736842105263\n",
      "Poly Kernel accuracy is:  0.84\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.8\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 6  5]\n",
      " [ 0 14]]\n",
      "RBF Kernel F1:  0.8484848484848484\n",
      "6 0 5 14\n",
      "RBF Kernel precision is:  1.0\n",
      "RBF Kernel recall is:  0.7368421052631579\n",
      "RBF Kernel accuracy is:  0.8\n",
      "-----------------------\n",
      "When C is  1000\n",
      "======================\n",
      "======================\n",
      "Linear Kernel\n",
      "=======================\n",
      "The Linear kernal returns:  0.88\n",
      "Linear Kernel Confusion Matrix: \n",
      "[[ 5  2]\n",
      " [ 1 17]]\n",
      "Linear Kernel F1:  0.918918918918919\n",
      "5 1 2 17\n",
      "Linear Kernel precision is:  0.9444444444444444\n",
      "Linear Kernel recall is:  0.8947368421052632\n",
      "Linear Kernel accuracy is:  0.88\n",
      "-----------------------\n",
      "Poly Kernel\n",
      "=======================\n",
      "The Poly kernal returns:  0.76\n",
      "Poly Kernel Confusion Matrix: \n",
      "[[ 5  5]\n",
      " [ 1 14]]\n",
      "Poly Kernel F1:  0.8235294117647058\n",
      "5 1 5 14\n",
      "Poly Kernel precision is:  0.9333333333333333\n",
      "Poly Kernel recall is:  0.7368421052631579\n",
      "Poly Kernel accuracy is:  0.76\n",
      "-----------------------\n",
      "RBF Kernel\n",
      "=======================\n",
      "The RBF kernal returns:  0.76\n",
      "RBF Kernel Confusion Matrix: \n",
      "[[ 5  5]\n",
      " [ 1 14]]\n",
      "RBF Kernel F1:  0.8235294117647058\n",
      "5 1 5 14\n",
      "RBF Kernel precision is:  0.9333333333333333\n",
      "RBF Kernel recall is:  0.7368421052631579\n",
      "RBF Kernel accuracy is:  0.76\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size = 0.30, \n",
    "random_state= 42)\n",
    "\n",
    "# authroized_or_not = (y == 0) | (y == 1)\n",
    "# X = X_train[authroized_or_not]\n",
    "# y = y_train[authroized_or_not]\n",
    "\n",
    "\n",
    "# SVM Classifier model\n",
    "C = [1,10,100,1000]\n",
    "y_predict = []\n",
    "for x in C:\n",
    "    print(\"When C is \", x)\n",
    "    print(\"======================\")\n",
    "    print(\"======================\")\n",
    "\n",
    "    name = \"Linear Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    svm_clf = SVC(kernel=\"linear\", C=x) #using C=1\n",
    "    # svm_clf.fit(X, y)\n",
    "    # #predict on test data\n",
    "    # #providing test data for petal length and width and testing the model.\n",
    "    #Actual label is 0.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Linear kernal returns: \", tmp)\n",
    "    \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"Poly Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "\n",
    "    svm_clf = SVC(kernel='poly', degree=2,C=x) #polynomial kernel with degree 2.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "\n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The Poly kernal returns: \", tmp)\n",
    "\n",
    "        \n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    name = \"RBF Kernel\"\n",
    "    print(name)\n",
    "    print(\"=======================\")\n",
    "    \n",
    "    svm_clf = SVC(kernel='rbf', gamma=1,C=x) #gaussian rbf kernel.\n",
    "    svm_clf.fit(X_train,y_train)\n",
    "    \n",
    "    tmp = svm_clf.score(X_test,y_test)\n",
    "    print(\"The RBF kernal returns: \", tmp)\n",
    "\n",
    "    y_predict = svm_clf.predict(X_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "    print(name, \"Confusion Matrix: \")\n",
    "    print(confusion_matrix)\n",
    "    F1 = f1_score(y_predict,y_test)\n",
    "    print(name, \"F1: \", F1)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(name, \"precision is: \", tp/(tp+fp))\n",
    "    print(name, \"recall is: \", tp/(tp+fn))\n",
    "    print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# print(\"The average prediction value is\",round(scores.mean(),3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Decision Tree returns:  0.68\n",
      "Decision Tree Confusion Matrix: \n",
      "[[ 6  8]\n",
      " [ 0 11]]\n",
      "Decision Tree F1:  0.7333333333333334\n",
      "6 0 8 11\n",
      "Decision Tree precision is:  1.0\n",
      "Decision Tree recall is:  0.5789473684210527\n",
      "Decision Tree accuracy is:  0.68\n",
      "=======================\n",
      "Random Forest returns:  0.88\n",
      "Random Forest Confusion Matrix: \n",
      "[[ 6  3]\n",
      " [ 0 16]]\n",
      "Random Forest F1:  0.9142857142857143\n",
      "6 0 3 16\n",
      "Random Forest precision is:  1.0\n",
      "Random Forest recall is:  0.8421052631578947\n",
      "Random Forest accuracy is:  0.88\n",
      "=======================\n",
      "XGBoost returns:  0.8\n",
      "XGBoost Confusion Matrix: \n",
      "[[ 6  5]\n",
      " [ 0 14]]\n",
      "XGBoost F1:  0.8484848484848484\n",
      "6 0 5 14\n",
      "XGBoost precision is:  1.0\n",
      "XGBoost recall is:  0.7368421052631579\n",
      "XGBoost accuracy is:  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#repeate for decision tree, random forest, XGBoost\n",
    "\n",
    "name = \"Decision Tree\"\n",
    "print(\"=======================\")\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Decision Tree returns: \", tmp)\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(\"Decision Tree Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(\"Decision Tree F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"Random Forest\"\n",
    "print(\"=======================\")\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = clf.score(X_test,y_test)\n",
    "print(\"Random Forest returns: \", tmp)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name = \"XGBoost\"\n",
    "print(\"=======================\")\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "tmp = tmp = clf.score(X_test,y_test)\n",
    "print(\"XGBoost returns: \", tmp)\n",
    "\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(y_predict,y_test)\n",
    "print(name, \"Confusion Matrix: \")\n",
    "print(confusion_matrix)\n",
    "F1 = f1_score(y_predict,y_test)\n",
    "print(name, \"F1: \", F1)\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(name, \"precision is: \", tp/(tp+fp))\n",
    "print(name, \"recall is: \", tp/(tp+fn))\n",
    "print(name, \"accuracy is: \", (tp+tn)/(tp+tn+fp+fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 19:07:14.202741: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 3ms/step - loss: 0.6561 - accuracy: 0.6316\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.7193\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.7368\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.7368\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.7544\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7719\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7719\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.7544\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6438 - accuracy: 0.7895\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7895\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.7895\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.7895\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.8070\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.8070\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.8246\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.8246\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.8070\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.8070\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.8070\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.8070\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.8070\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8070\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.8070\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.8070\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.8070\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.8070\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6149 - accuracy: 0.8070\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.8070\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.8070\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.8070\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6078 - accuracy: 0.8070\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.8246\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.8246\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6016 - accuracy: 0.8246\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.8246\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.8246\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8246\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.8246\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5935 - accuracy: 0.8246\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.8246\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5904 - accuracy: 0.8246\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.8070\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.8070\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.8070\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.8070\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.8070\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.8070\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.7895\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5788 - accuracy: 0.7895\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5776 - accuracy: 0.7895\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7895\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.7895\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7895\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7895\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7895\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.8070\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.8070\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.8070\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.8070\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7895\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7895\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7895\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.7895\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7895\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7895\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7895\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.8070\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.8070\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5527 - accuracy: 0.8070\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5515 - accuracy: 0.8070\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.8070\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.8070\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.8070\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8070\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.8070\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.8070\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5428 - accuracy: 0.8070\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.8070\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.8070\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.8070\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.8070\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.8070\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.8070\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.8070\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5332 - accuracy: 0.8070\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.8070\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.8070\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.8070\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.8070\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5276 - accuracy: 0.8070\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.8070\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.8070\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8070\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8070\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8070\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8070\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8070\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8246\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8246\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Accuracy for NN: 0.88\n",
      "Precision for NN: 0.8636363636363636\n",
      "Recall for NN: 1.0\n",
      "F1 score for NN: 0.9268292682926829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=5, activation=\"relu\",input_shape=(8,)),\n",
    "    Dense(units=3, activation=\"relu\"),\n",
    "    Dense(units=1, activation=\"sigmoid\")])\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "predicted = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Accuracy \n",
    "Accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy for NN:\",Accuracy)\n",
    "\n",
    "# Precision\n",
    "Precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Precision for NN:\",Precision)\n",
    "\n",
    "# Recall\n",
    "Recall = metrics.recall_score(y_test, predicted)\n",
    "print(\"Recall for NN:\",Recall)\n",
    "\n",
    "# F1 score\n",
    "F1_score = metrics.f1_score(y_test, predicted)\n",
    "print(\"F1 score for NN:\",F1_score)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.6491\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6970 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6945 - accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6876 - accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6837 - accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6831 - accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6810 - accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.6667\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6667\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6667\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6667\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6706 - accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.6667\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6667\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6674 - accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.6667\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.6667\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6667\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.6667\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.6667\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.6667\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6667\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.6667\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6625 - accuracy: 0.6667\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6617 - accuracy: 0.6667\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.6667\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6667\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6667\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6592 - accuracy: 0.6667\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6667\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.6667\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.6667\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.6667\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.6667\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6667\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6667\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6667\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6667\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.6667\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6667\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6667\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6667\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6667\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6667\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6667\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6667\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.6667\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6667\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6667\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Accuracy for NN: 0.76\n",
      "Precision for NN: 0.76\n",
      "Recall for NN: 1.0\n",
      "F1 score for NN: 0.8636363636363636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=4, activation=\"relu\",input_shape=(8,)),\n",
    "    Dense(units=1, activation=\"sigmoid\")])\n",
    "model.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "predicted = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Accuracy \n",
    "Accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy for NN:\",Accuracy)\n",
    "\n",
    "# Precision\n",
    "Precision = metrics.precision_score(y_test, predicted)\n",
    "print(\"Precision for NN:\",Precision)\n",
    "\n",
    "# Recall\n",
    "Recall = metrics.recall_score(y_test, predicted)\n",
    "print(\"Recall for NN:\",Recall)\n",
    "\n",
    "# F1 score\n",
    "F1_score = metrics.f1_score(y_test, predicted)\n",
    "print(\"F1 score for NN:\",F1_score)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
